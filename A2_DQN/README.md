# Overview
requirements-option1.txt contains list of dependencies.

dqn_base_class.py contains the agent and environment. many_dqn_wrapper.py adds multiprocessing for deep Q learning agent.

Run plot_rewards.py for plots shown in report (requires saved rewards from BATCHES folder)

If you wish to run any experiments yourself, Experiment.py runs the agent/environment (using many_dqn_wrapper) and saves rewards and DQN weights. Change the parameters in main() depending on which settings you wish to run.

Additional supplementary functions located in helper.py.



# Read Me:
## Use:
TLDR:
1. 

### Preparation
1. 
### Running the DQN
1. 
### Analyzing the DQNResult
1. 

---
---

## Authors & Copyleft
See project overview for authors.

## To Dos:
### ESSENTIAL:
- [ ] Save rewards, save network (model.save) use try: except
- [ ] Multithread agents
- [ ] Experiment.py - defaults: alpha=0.25, method:e-greedy, epsilon=0.05, discount=1., layers=2, neurons=(12, 6)
- [ ] Plotting (CI, axis etc)
- [ ] 
- [ ] 
- [ ] Export environment.yml file
- [ ] Export requirements.txt file

### Backend:
- [ ] 
- [ ] 
- [ ] 
- [ ] 
- [ ] 
- [ ] 


### Plotting:
- [ ] 
- [ ] 


### Expand Scope:
- [ ] Buffers
- [ ] 


### Prettyfication: (most important)
- [ ] 
- [ ] 

